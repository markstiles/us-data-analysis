{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFQ-MfputVCV",
        "outputId": "1dd244b0-3a1e-4974-afd8-73e68e051668"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch-summary\n",
            "  Downloading torch_summary-1.4.5-py3-none-any.whl (16 kB)\n",
            "Installing collected packages: torch-summary\n",
            "Successfully installed torch-summary-1.4.5\n"
          ]
        }
      ],
      "source": [
        "! pip install torchviz -q\n",
        "! pip install torch-summary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO\n",
        "# get normalization into the model\n",
        "# get rid of pandas\n",
        "# can we get categorical layer built into the model\n",
        "# ui to plug in some changes to values and state to test what changes to a state might look like\n",
        "# use embeddings for the categorical\n",
        "# track the best MSE and try to store the model for deployment"
      ],
      "metadata": {
        "id": "QtjX2vjZylA8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# namespaces\n",
        "import copy\n",
        "import numpy as np\n",
        "import matplotlib.patches as mpatches\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import plotly.io as pio\n",
        "pio.renderers.default = 'notebook'\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import tqdm\n",
        "\n",
        "# functions\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchsummary import summary\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "5jd4whyVtXyQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get data, drop index column and zero the blanks\n",
        "places_df = pd.read_csv('https://raw.githubusercontent.com/markstiles/us-data-analysis/main/places_data.csv')\n",
        "places_df.drop(places_df.columns[[0]], axis=1, inplace=True)\n",
        "places_df = places_df.fillna(0)"
      ],
      "metadata": {
        "id": "1oN5WT2WtZuH"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build a one-hot by state and attach it\n",
        "state_dummies = pd.get_dummies(places_df.State_Name)\n",
        "places_df = pd.concat([places_df, state_dummies.set_axis(places_df.index)], axis=1)"
      ],
      "metadata": {
        "id": "8RQreyYsbOCw"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get rid of the locations and sparse data\n",
        "drop_cols = [\n",
        " 'Place_Name', 'State_Abbr', 'State_Name', 'Type', 'All_Employers', 'All_Employees', 'All_Payroll',\n",
        " 'Agriculture_Employers','Agriculture_Employees','Agriculture_Payroll','Agriculture_Revenue',\n",
        " 'Construction_Employers','Construction_Employees','Construction_Payroll','Construction_Revenue',\n",
        " 'Finance_Revenue',\n",
        " 'Information_Revenue',\n",
        " 'Management_Employers','Management_Employees','Management_Payroll','Management_Revenue',\n",
        " 'Manufacturing_Employers','Manufacturing_Employees','Manufacturing_Payroll','Manufacturing_Revenue',\n",
        " 'Mining_Employers','Mining_Employees','Mining_Payroll','Mining_Revenue',\n",
        " 'Utilities_Revenue',\n",
        " 'Wholesale_Employers','Wholesale_Employees','Wholesale_Payroll','Wholesale_Revenue',\n",
        " 'Consumer_Total_Expense','Consumer_Expense_Alcohol','Consumer_Expense_Alcohol_Home','Consumer_Expense_Beer_Bar','Consumer_Expense_Wine_Bar','Consumer_Expense_Clothes','Consumer_Expense_Mens_Clothes',\n",
        " 'Consumer_Expense_Womens_Clothes','Consumer_Expense_Childrens_Clothes','Consumer_Expense_Boys_Clothes','Consumer_Expense_Girls_Clothes','Consumer_Expense_Footwear','Consumer_Expense_Dining',\n",
        " 'Consumer_Expense_Dining_Breakfast','Consumer_Expense_Dining_Lunch','Consumer_Expense_Dining_Dinner','Consumer_Expense_Education','Consumer_Expense_Entertainment','Consumer_Expense_Clubs',\n",
        " 'Consumer_Expense_Dating','Consumer_Expense_Pet_Food','Consumer_Expense_Pet_Services','Consumer_Expense_Food_Home','Consumer_Expense_Bakery_Home','Consumer_Expense_Dairy_Home','Consumer_Expense_Fruits_Home',\n",
        " 'Consumer_Expense_Meat_Home','Consumer_Expense_Nonalcohol_Home','Consumer_Expense_Snacks_Home','Consumer_Expense_Healthcare','Consumer_Expense_Mentalcare','Consumer_Expense_Drugcar','Consumer_Expense_House_Services',\n",
        " 'Consumer_Expense_Eldercare','Consumer_Expense_Landscape','Consumer_Expense_Housekeeping','Consumer_Expense_PC','Consumer_Expense_Housing','Consumer_Expense_Home_Improvements','Consumer_Expense_Energy',\n",
        " 'Consumer_Expense_Phone','Consumer_Expense_Water','Consumer_Expense_Insurance','Consumer_Expense_Pensions','Consumer_Expense_Personalcare','Consumer_Expense_Haircare','Consumer_Expense_Personalcare_Products',\n",
        " 'Consumer_Expense_Transport','Consumer_Expense_Gas','Consumer_Expense_Vehicle_Repair','Consumer_Expense_Travel','Consumer_Expense_Airfare','Consumer_Expense_Auto_Rentals','Consumer_Expense_Travel_Lodging',\n",
        " 'Consumer_Expense_Travel_Meals','Consumer_Expense_Travel_Entertainment',\n",
        " 'All_Employee_Per_Employer','All_Revenue_Per_Employer','All_Avg_Payroll_Per_Employee','All_Population_Per_Employer',\n",
        " 'Food_Services_Employee_Per_Employer','Food_Services_Revenue_Per_Employer','Food_Services_Avg_Payroll_Per_Employee','Food_Services_Population_Per_Employer','Waste_Management_Employee_Per_Employer',\n",
        " 'Waste_Management_Revenue_Per_Employer','Waste_Management_Avg_Payroll_Per_Employee','Waste_Management_Population_Per_Employer','Agriculture_Employee_Per_Employer','Agriculture_Revenue_Per_Employer',\n",
        " 'Agriculture_Avg_Payroll_Per_Employee','Agriculture_Population_Per_Employer','Arts_Employee_Per_Employer','Arts_Revenue_Per_Employer','Arts_Avg_Payroll_Per_Employee','Arts_Population_Per_Employer',\n",
        " 'Construction_Employee_Per_Employer','Construction_Revenue_Per_Employer','Construction_Avg_Payroll_Per_Employee','Construction_Population_Per_Employer','Education_Employee_Per_Employer',\n",
        " 'Education_Revenue_Per_Employer','Education_Avg_Payroll_Per_Employee','Education_Population_Per_Employer','Finance_Employee_Per_Employer','Finance_Revenue_Per_Employer','Finance_Avg_Payroll_Per_Employee',\n",
        " 'Finance_Population_Per_Employer','Healthcare_Employee_Per_Employer','Healthcare_Revenue_Per_Employer','Healthcare_Avg_Payroll_Per_Employee','Healthcare_Population_Per_Employer','Information_Employee_Per_Employer',\n",
        " 'Information_Revenue_Per_Employer','Information_Avg_Payroll_Per_Employee','Information_Population_Per_Employer','Management_Employee_Per_Employer','Management_Revenue_Per_Employer','Management_Avg_Payroll_Per_Employee',\n",
        " 'Management_Population_Per_Employer','Manufacturing_Employee_Per_Employer','Manufacturing_Revenue_Per_Employer','Manufacturing_Avg_Payroll_Per_Employee','Manufacturing_Population_Per_Employer','Mining_Employee_Per_Employer',\n",
        " 'Mining_Revenue_Per_Employer','Mining_Avg_Payroll_Per_Employee','Mining_Population_Per_Employer','Other_Employee_Per_Employer','Other_Revenue_Per_Employer','Other_Avg_Payroll_Per_Employee','Other_Population_Per_Employer',\n",
        " 'Technical_Employee_Per_Employer','Technical_Revenue_Per_Employer','Technical_Avg_Payroll_Per_Employee','Technical_Population_Per_Employer','Real_Estate_Employee_Per_Employer','Real_Estate_Revenue_Per_Employer',\n",
        " 'Real_Estate_Avg_Payroll_Per_Employee','Real_Estate_Population_Per_Employer','Retail_Employee_Per_Employer','Retail_Revenue_Per_Employer','Retail_Avg_Payroll_Per_Employee','Retail_Population_Per_Employer',\n",
        " 'Transportation_Employee_Per_Employer','Transportation_Revenue_Per_Employer','Transportation_Avg_Payroll_Per_Employee','Transportation_Population_Per_Employer','Utilities_Employee_Per_Employer','Utilities_Revenue_Per_Employer',\n",
        " 'Utilities_Avg_Payroll_Per_Employee','Utilities_Population_Per_Employer','Wholesale_Employee_Per_Employer','Wholesale_Revenue_Per_Employer','Wholesale_Avg_Payroll_Per_Employee','Wholesale_Population_Per_Employer',\n",
        " 'Income_Per_Revenue',\n",
        " 'Revenue_Per_Person','Profit_Per_Person',\n",
        " 'Population_Range', 'Performance'\n",
        "]\n",
        "places_df.drop(columns=drop_cols, inplace=True)"
      ],
      "metadata": {
        "id": "MN9iAPfpiqL_"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop the top skewing outliers\n",
        "places_df = places_df[places_df.All_Revenue < 20000000]"
      ],
      "metadata": {
        "id": "JkGKQzXp2oji"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set the y to revenue\n",
        "y = places_df['All_Revenue'].to_numpy()\n",
        "# remove the identifier and target columns\n",
        "x = places_df.drop(columns=['GeoId', 'All_Revenue'])\n",
        "x.shape"
      ],
      "metadata": {
        "id": "tBufAt5_tfj4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0669f81e-4902-4972-987a-03b38cad899f"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9720, 174)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(x)\n",
        "fit_data = scaler.transform(x)"
      ],
      "metadata": {
        "id": "24SkkOvhtfhn"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train-test split for model evaluation\n",
        "x_train, x_test, y_train, y_test = train_test_split(fit_data, y, train_size=0.7, shuffle=True)\n",
        "\n",
        "# convert to 2d pytorch tensors\n",
        "x_train = torch.tensor(x_train, dtype=torch.float32)\n",
        "y_train = torch.tensor(y_train, dtype=torch.float32).reshape(-1, 1)\n",
        "x_test = torch.tensor(x_test, dtype=torch.float32)\n",
        "y_test = torch.tensor(y_test, dtype=torch.float32).reshape(-1, 1)"
      ],
      "metadata": {
        "id": "mHLpWLxGverm"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the model\n",
        "model = nn.Sequential(\n",
        "    nn.Linear(x.shape[1], 2048),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(2048, 1024),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(1024, 2048),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(2048, 512),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(512, 1)\n",
        ")\n",
        "\n",
        "# set the weights for the regression model\n",
        "def init_weights(m):\n",
        "    if isinstance(m, nn.Linear):\n",
        "        torch.nn.init.xavier_uniform_(m.weight)\n",
        "        m.bias.data.fill_(0.01)\n",
        "\n",
        "model.apply(init_weights)\n",
        "\n",
        "# loss function and optimizer\n",
        "loss_fn = nn.MSELoss()  # mean square error\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# hold the best model\n",
        "best_mse = np.inf   # init to infinity\n",
        "best_weights = None\n",
        "train_history = []\n",
        "test_history = []"
      ],
      "metadata": {
        "id": "FMFjoTgFwS7W"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = 1000   # number of epochs to run\n",
        "batch_size = 200  # size of each batch\n",
        "batch_start = torch.arange(0, len(x_train), batch_size)\n",
        "step_count = 0\n",
        "step_size = 100"
      ],
      "metadata": {
        "id": "lTeq_LkBwoKG"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    with tqdm.tqdm(batch_start, unit=\"batch\", mininterval=0, disable=False) as bar:\n",
        "        bar.set_description(f\"Epoch {epoch}\")\n",
        "        for start in bar:\n",
        "            # take a batch\n",
        "            x_batch = x_train[start:start+batch_size]\n",
        "            y_batch = y_train[start:start+batch_size]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # forward pass\n",
        "            y_pred = model(x_batch)\n",
        "            loss = loss_fn(y_pred, y_batch)\n",
        "            if step_count % step_size == 0:\n",
        "              train_history.append(loss.item())\n",
        "              with torch.no_grad():\n",
        "                  y_test_pred = model(x_test)\n",
        "                  test_loss = loss_fn(y_test_pred.float(), y_test)\n",
        "                  test_history.append(test_loss.item())\n",
        "\n",
        "            # backward pass\n",
        "            loss.backward()\n",
        "\n",
        "            # update weights\n",
        "            optimizer.step()\n",
        "\n",
        "            # print progress\n",
        "            bar.set_postfix(mse=float(loss))\n",
        "\n",
        "            step_count += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5S_gSiotfxp",
        "outputId": "14736263-b396-43ef-d4ed-f6f96e28abc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0: 100%|██████████| 35/35 [00:04<00:00,  7.48batch/s, mse=1.9e+12]\n",
            "Epoch 1: 100%|██████████| 35/35 [00:03<00:00,  9.42batch/s, mse=8.98e+11]\n",
            "Epoch 2: 100%|██████████| 35/35 [00:04<00:00,  8.58batch/s, mse=7e+10]\n",
            "Epoch 3: 100%|██████████| 35/35 [00:04<00:00,  8.37batch/s, mse=3.9e+9]\n",
            "Epoch 4: 100%|██████████| 35/35 [00:03<00:00,  9.63batch/s, mse=3.28e+9]\n",
            "Epoch 5: 100%|██████████| 35/35 [00:03<00:00,  8.77batch/s, mse=1.56e+9]\n",
            "Epoch 6: 100%|██████████| 35/35 [00:04<00:00,  8.54batch/s, mse=6.59e+8]\n",
            "Epoch 7: 100%|██████████| 35/35 [00:03<00:00,  9.62batch/s, mse=6.19e+8]\n",
            "Epoch 8: 100%|██████████| 35/35 [00:04<00:00,  8.74batch/s, mse=1.35e+9]\n",
            "Epoch 9: 100%|██████████| 35/35 [00:03<00:00,  8.95batch/s, mse=1.99e+9]\n",
            "Epoch 10: 100%|██████████| 35/35 [00:03<00:00,  9.12batch/s, mse=2.58e+9]\n",
            "Epoch 11: 100%|██████████| 35/35 [00:03<00:00,  8.82batch/s, mse=2.7e+9]\n",
            "Epoch 12: 100%|██████████| 35/35 [00:03<00:00,  9.39batch/s, mse=2.23e+9]\n",
            "Epoch 13: 100%|██████████| 35/35 [00:04<00:00,  8.60batch/s, mse=1.32e+9]\n",
            "Epoch 14: 100%|██████████| 35/35 [00:04<00:00,  8.75batch/s, mse=7.98e+8]\n",
            "Epoch 15: 100%|██████████| 35/35 [00:03<00:00,  9.62batch/s, mse=4.77e+8]\n",
            "Epoch 16: 100%|██████████| 35/35 [00:04<00:00,  8.35batch/s, mse=3.64e+8]\n",
            "Epoch 17: 100%|██████████| 35/35 [00:04<00:00,  8.69batch/s, mse=2.93e+8]\n",
            "Epoch 18: 100%|██████████| 35/35 [00:03<00:00,  9.69batch/s, mse=2.96e+8]\n",
            "Epoch 19: 100%|██████████| 35/35 [00:04<00:00,  8.38batch/s, mse=3.64e+8]\n",
            "Epoch 20: 100%|██████████| 35/35 [00:04<00:00,  8.74batch/s, mse=3.24e+8]\n",
            "Epoch 21: 100%|██████████| 35/35 [00:03<00:00,  9.65batch/s, mse=2.82e+8]\n",
            "Epoch 22: 100%|██████████| 35/35 [00:04<00:00,  7.77batch/s, mse=2.49e+8]\n",
            "Epoch 23: 100%|██████████| 35/35 [00:03<00:00,  9.47batch/s, mse=2.35e+8]\n",
            "Epoch 24: 100%|██████████| 35/35 [00:03<00:00,  9.74batch/s, mse=2.16e+8]\n",
            "Epoch 25: 100%|██████████| 35/35 [00:04<00:00,  8.29batch/s, mse=1.9e+8]\n",
            "Epoch 26: 100%|██████████| 35/35 [00:03<00:00,  9.07batch/s, mse=1.94e+8]\n",
            "Epoch 27: 100%|██████████| 35/35 [00:03<00:00,  9.55batch/s, mse=1.32e+8]\n",
            "Epoch 28: 100%|██████████| 35/35 [00:04<00:00,  8.66batch/s, mse=1.09e+8]\n",
            "Epoch 29: 100%|██████████| 35/35 [00:04<00:00,  8.53batch/s, mse=6.97e+7]\n",
            "Epoch 30: 100%|██████████| 35/35 [00:03<00:00,  9.65batch/s, mse=4.63e+7]\n",
            "Epoch 31: 100%|██████████| 35/35 [00:03<00:00,  8.78batch/s, mse=2.87e+7]\n",
            "Epoch 32: 100%|██████████| 35/35 [00:04<00:00,  8.39batch/s, mse=1.47e+7]\n",
            "Epoch 33: 100%|██████████| 35/35 [00:03<00:00,  9.68batch/s, mse=4.58e+6]\n",
            "Epoch 34: 100%|██████████| 35/35 [00:04<00:00,  8.66batch/s, mse=9.96e+5]\n",
            "Epoch 35: 100%|██████████| 35/35 [00:04<00:00,  8.36batch/s, mse=2.96e+6]\n",
            "Epoch 36: 100%|██████████| 35/35 [00:03<00:00,  9.52batch/s, mse=7.81e+6]\n",
            "Epoch 37: 100%|██████████| 35/35 [00:04<00:00,  8.68batch/s, mse=1.89e+7]\n",
            "Epoch 38: 100%|██████████| 35/35 [00:04<00:00,  8.75batch/s, mse=1.38e+7]\n",
            "Epoch 39: 100%|██████████| 35/35 [00:03<00:00,  9.06batch/s, mse=1.65e+7]\n",
            "Epoch 40: 100%|██████████| 35/35 [00:04<00:00,  8.63batch/s, mse=1.49e+7]\n",
            "Epoch 41: 100%|██████████| 35/35 [00:03<00:00,  9.27batch/s, mse=1.41e+7]\n",
            "Epoch 42: 100%|██████████| 35/35 [00:04<00:00,  7.85batch/s, mse=1.07e+7]\n",
            "Epoch 43: 100%|██████████| 35/35 [00:03<00:00,  9.49batch/s, mse=6.94e+6]\n",
            "Epoch 44: 100%|██████████| 35/35 [00:03<00:00,  9.61batch/s, mse=1.42e+7]\n",
            "Epoch 45: 100%|██████████| 35/35 [00:04<00:00,  7.75batch/s, mse=5.8e+6]\n",
            "Epoch 46: 100%|██████████| 35/35 [00:03<00:00,  9.55batch/s, mse=4.26e+6]\n",
            "Epoch 47: 100%|██████████| 35/35 [00:03<00:00,  9.75batch/s, mse=9.8e+6]\n",
            "Epoch 48: 100%|██████████| 35/35 [00:04<00:00,  7.43batch/s, mse=3.13e+6]\n",
            "Epoch 49: 100%|██████████| 35/35 [00:04<00:00,  8.75batch/s, mse=2.57e+6]\n",
            "Epoch 50: 100%|██████████| 35/35 [00:03<00:00,  8.76batch/s, mse=7.38e+6]\n",
            "Epoch 51: 100%|██████████| 35/35 [00:04<00:00,  7.47batch/s, mse=3.78e+6]\n",
            "Epoch 52: 100%|██████████| 35/35 [00:03<00:00,  9.56batch/s, mse=8.3e+6]\n",
            "Epoch 53: 100%|██████████| 35/35 [00:03<00:00,  9.60batch/s, mse=6.56e+6]\n",
            "Epoch 54: 100%|██████████| 35/35 [00:04<00:00,  7.86batch/s, mse=6.86e+7]\n",
            "Epoch 55: 100%|██████████| 35/35 [00:03<00:00,  9.44batch/s, mse=1.06e+7]\n",
            "Epoch 56: 100%|██████████| 35/35 [00:03<00:00,  9.61batch/s, mse=1.54e+7]\n",
            "Epoch 57: 100%|██████████| 35/35 [00:04<00:00,  8.14batch/s, mse=3.99e+7]\n",
            "Epoch 58: 100%|██████████| 35/35 [00:03<00:00,  9.06batch/s, mse=7.21e+6]\n",
            "Epoch 59: 100%|██████████| 35/35 [00:03<00:00,  9.63batch/s, mse=2.25e+7]\n",
            "Epoch 60: 100%|██████████| 35/35 [00:04<00:00,  8.65batch/s, mse=6.3e+7]\n",
            "Epoch 61: 100%|██████████| 35/35 [00:04<00:00,  8.50batch/s, mse=4.76e+7]\n",
            "Epoch 62: 100%|██████████| 35/35 [00:04<00:00,  8.73batch/s, mse=6.86e+7]\n",
            "Epoch 63: 100%|██████████| 35/35 [00:03<00:00,  9.62batch/s, mse=5.14e+7]\n",
            "Epoch 64: 100%|██████████| 35/35 [00:04<00:00,  8.37batch/s, mse=5.35e+7]\n",
            "Epoch 65: 100%|██████████| 35/35 [00:04<00:00,  8.70batch/s, mse=4.76e+7]\n",
            "Epoch 66: 100%|██████████| 35/35 [00:03<00:00,  9.55batch/s, mse=2.98e+7]\n",
            "Epoch 67: 100%|██████████| 35/35 [00:04<00:00,  8.44batch/s, mse=1.59e+7]\n",
            "Epoch 68: 100%|██████████| 35/35 [00:04<00:00,  8.69batch/s, mse=1.88e+7]\n",
            "Epoch 69: 100%|██████████| 35/35 [00:03<00:00,  9.60batch/s, mse=4.42e+7]\n",
            "Epoch 70: 100%|██████████| 35/35 [00:03<00:00,  8.86batch/s, mse=4.98e+7]\n",
            "Epoch 71: 100%|██████████| 35/35 [00:04<00:00,  8.25batch/s, mse=4.31e+7]\n",
            "Epoch 72: 100%|██████████| 35/35 [00:03<00:00,  9.60batch/s, mse=3.56e+7]\n",
            "Epoch 73: 100%|██████████| 35/35 [00:03<00:00,  9.39batch/s, mse=4.32e+7]\n",
            "Epoch 74: 100%|██████████| 35/35 [00:04<00:00,  7.83batch/s, mse=2.85e+7]\n",
            "Epoch 75: 100%|██████████| 35/35 [00:03<00:00,  9.64batch/s, mse=1.05e+7]\n",
            "Epoch 76: 100%|██████████| 35/35 [00:03<00:00,  9.59batch/s, mse=3.87e+7]\n",
            "Epoch 77: 100%|██████████| 35/35 [00:04<00:00,  7.72batch/s, mse=1.96e+7]\n",
            "Epoch 78: 100%|██████████| 35/35 [00:03<00:00,  9.63batch/s, mse=3.35e+6]\n",
            "Epoch 79: 100%|██████████| 35/35 [00:03<00:00,  9.69batch/s, mse=1.82e+7]\n",
            "Epoch 80: 100%|██████████| 35/35 [00:04<00:00,  7.77batch/s, mse=2.49e+7]\n",
            "Epoch 81: 100%|██████████| 35/35 [00:03<00:00,  9.69batch/s, mse=1.17e+7]\n",
            "Epoch 82: 100%|██████████| 35/35 [00:04<00:00,  8.67batch/s, mse=1.19e+7]\n",
            "Epoch 83: 100%|██████████| 35/35 [00:04<00:00,  8.60batch/s, mse=1.87e+7]\n",
            "Epoch 84: 100%|██████████| 35/35 [00:03<00:00,  9.28batch/s, mse=1.7e+7]\n",
            "Epoch 85: 100%|██████████| 35/35 [00:04<00:00,  8.66batch/s, mse=2.6e+6]\n",
            "Epoch 86: 100%|██████████| 35/35 [00:03<00:00,  9.06batch/s, mse=1.62e+7]\n",
            "Epoch 87: 100%|██████████| 35/35 [00:03<00:00,  9.01batch/s, mse=1.23e+7]\n",
            "Epoch 88: 100%|██████████| 35/35 [00:04<00:00,  8.67batch/s, mse=2.14e+7]\n",
            "Epoch 89: 100%|██████████| 35/35 [00:03<00:00,  9.64batch/s, mse=1.79e+7]\n",
            "Epoch 90: 100%|██████████| 35/35 [00:04<00:00,  8.36batch/s, mse=7.75e+6]\n",
            "Epoch 91: 100%|██████████| 35/35 [00:04<00:00,  8.75batch/s, mse=1.89e+6]\n",
            "Epoch 92: 100%|██████████| 35/35 [00:03<00:00,  9.48batch/s, mse=4.31e+6]\n",
            "Epoch 93: 100%|██████████| 35/35 [00:04<00:00,  8.35batch/s, mse=2.01e+7]\n",
            "Epoch 94: 100%|██████████| 35/35 [00:04<00:00,  8.69batch/s, mse=5.02e+7]\n",
            "Epoch 95: 100%|██████████| 35/35 [00:03<00:00,  9.59batch/s, mse=5.25e+8]\n",
            "Epoch 96: 100%|██████████| 35/35 [00:04<00:00,  8.51batch/s, mse=2.22e+9]\n",
            "Epoch 97: 100%|██████████| 35/35 [00:04<00:00,  8.66batch/s, mse=4.21e+9]\n",
            "Epoch 98: 100%|██████████| 35/35 [00:03<00:00,  9.59batch/s, mse=4.27e+9]\n",
            "Epoch 99: 100%|██████████| 35/35 [00:03<00:00,  8.95batch/s, mse=9.28e+8]\n",
            "Epoch 100: 100%|██████████| 35/35 [00:04<00:00,  8.16batch/s, mse=7.22e+9]\n",
            "Epoch 101: 100%|██████████| 35/35 [00:03<00:00,  9.53batch/s, mse=6.5e+9]\n",
            "Epoch 102: 100%|██████████| 35/35 [00:04<00:00,  8.36batch/s, mse=1.47e+9]\n",
            "Epoch 103: 100%|██████████| 35/35 [00:04<00:00,  8.72batch/s, mse=3.72e+8]\n",
            "Epoch 104: 100%|██████████| 35/35 [00:03<00:00,  9.55batch/s, mse=5.5e+7]\n",
            "Epoch 105: 100%|██████████| 35/35 [00:04<00:00,  8.64batch/s, mse=7.83e+8]\n",
            "Epoch 106: 100%|██████████| 35/35 [00:04<00:00,  8.38batch/s, mse=6.66e+8]\n",
            "Epoch 107: 100%|██████████| 35/35 [00:03<00:00,  9.53batch/s, mse=2.25e+8]\n",
            "Epoch 108: 100%|██████████| 35/35 [00:04<00:00,  8.66batch/s, mse=3.58e+8]\n",
            "Epoch 109: 100%|██████████| 35/35 [00:04<00:00,  8.49batch/s, mse=9.32e+8]\n",
            "Epoch 110: 100%|██████████| 35/35 [00:03<00:00,  9.57batch/s, mse=6.22e+7]\n",
            "Epoch 111: 100%|██████████| 35/35 [00:04<00:00,  8.70batch/s, mse=2.4e+9]\n",
            "Epoch 112: 100%|██████████| 35/35 [00:04<00:00,  8.67batch/s, mse=1.91e+9]\n",
            "Epoch 113: 100%|██████████| 35/35 [00:03<00:00,  9.25batch/s, mse=5.1e+8]\n",
            "Epoch 114: 100%|██████████| 35/35 [00:04<00:00,  8.65batch/s, mse=2.88e+9]\n",
            "Epoch 115: 100%|██████████| 35/35 [00:03<00:00,  9.14batch/s, mse=9.73e+8]\n",
            "Epoch 116: 100%|██████████| 35/35 [00:03<00:00,  8.84batch/s, mse=1.23e+9]\n",
            "Epoch 117: 100%|██████████| 35/35 [00:04<00:00,  8.61batch/s, mse=2.91e+9]\n",
            "Epoch 118: 100%|██████████| 35/35 [00:03<00:00,  9.59batch/s, mse=1.66e+9]\n",
            "Epoch 119: 100%|██████████| 35/35 [00:04<00:00,  8.35batch/s, mse=6.01e+8]\n",
            "Epoch 120: 100%|██████████| 35/35 [00:04<00:00,  8.69batch/s, mse=5.2e+8]\n",
            "Epoch 121: 100%|██████████| 35/35 [00:03<00:00,  9.53batch/s, mse=1.12e+8]\n",
            "Epoch 122: 100%|██████████| 35/35 [00:04<00:00,  7.64batch/s, mse=9e+7]\n",
            "Epoch 123: 100%|██████████| 35/35 [00:03<00:00,  9.52batch/s, mse=5.49e+8]\n",
            "Epoch 124: 100%|██████████| 35/35 [00:03<00:00,  9.54batch/s, mse=8.78e+6]\n",
            "Epoch 125: 100%|██████████| 35/35 [00:04<00:00,  7.69batch/s, mse=1.77e+8]\n",
            "Epoch 126: 100%|██████████| 35/35 [00:03<00:00,  9.68batch/s, mse=4.77e+8]\n",
            "Epoch 127: 100%|██████████| 35/35 [00:03<00:00,  9.59batch/s, mse=4.86e+7]\n",
            "Epoch 128: 100%|██████████| 35/35 [00:04<00:00,  7.90batch/s, mse=4.13e+8]\n",
            "Epoch 129: 100%|██████████| 35/35 [00:03<00:00,  9.15batch/s, mse=3.5e+8]\n",
            "Epoch 130: 100%|██████████| 35/35 [00:03<00:00,  9.47batch/s, mse=1.45e+8]\n",
            "Epoch 131: 100%|██████████| 35/35 [00:04<00:00,  8.27batch/s, mse=7.61e+8]\n",
            "Epoch 132: 100%|██████████| 35/35 [00:03<00:00,  8.88batch/s, mse=6.07e+8]\n",
            "Epoch 133: 100%|██████████| 35/35 [00:03<00:00,  9.62batch/s, mse=1.13e+8]\n",
            "Epoch 134: 100%|██████████| 35/35 [00:04<00:00,  8.66batch/s, mse=1.39e+9]\n",
            "Epoch 135: 100%|██████████| 35/35 [00:04<00:00,  8.35batch/s, mse=2.67e+7]\n",
            "Epoch 136: 100%|██████████| 35/35 [00:03<00:00,  9.54batch/s, mse=4.76e+8]\n",
            "Epoch 137: 100%|██████████| 35/35 [00:04<00:00,  8.66batch/s, mse=4.48e+7]\n",
            "Epoch 138: 100%|██████████| 35/35 [00:04<00:00,  8.43batch/s, mse=6.7e+8]\n",
            "Epoch 139: 100%|██████████| 35/35 [00:03<00:00,  9.66batch/s, mse=1.43e+8]\n",
            "Epoch 140: 100%|██████████| 35/35 [00:04<00:00,  8.71batch/s, mse=1.49e+8]\n",
            "Epoch 141: 100%|██████████| 35/35 [00:04<00:00,  8.55batch/s, mse=8.9e+7]\n",
            "Epoch 142: 100%|██████████| 35/35 [00:04<00:00,  8.52batch/s, mse=1.66e+8]\n",
            "Epoch 143: 100%|██████████| 35/35 [00:03<00:00,  9.68batch/s, mse=6.57e+8]\n",
            "Epoch 144: 100%|██████████| 35/35 [00:03<00:00,  8.94batch/s, mse=2.34e+8]\n",
            "Epoch 145: 100%|██████████| 35/35 [00:04<00:00,  8.08batch/s, mse=1.72e+8]\n",
            "Epoch 146: 100%|██████████| 35/35 [00:03<00:00,  9.73batch/s, mse=2.01e+7]\n",
            "Epoch 147: 100%|██████████| 35/35 [00:03<00:00,  9.56batch/s, mse=4.08e+8]\n",
            "Epoch 148: 100%|██████████| 35/35 [00:04<00:00,  7.69batch/s, mse=4.27e+8]\n",
            "Epoch 149: 100%|██████████| 35/35 [00:03<00:00,  9.65batch/s, mse=1.13e+8]\n",
            "Epoch 150: 100%|██████████| 35/35 [00:03<00:00,  9.62batch/s, mse=1.06e+8]\n",
            "Epoch 151: 100%|██████████| 35/35 [00:04<00:00,  7.72batch/s, mse=1.42e+8]\n",
            "Epoch 152: 100%|██████████| 35/35 [00:03<00:00,  9.49batch/s, mse=1.2e+8]\n",
            "Epoch 153: 100%|██████████| 35/35 [00:03<00:00,  9.59batch/s, mse=3.93e+8]\n",
            "Epoch 154: 100%|██████████| 35/35 [00:04<00:00,  7.73batch/s, mse=1.64e+9]\n",
            "Epoch 155: 100%|██████████| 35/35 [00:03<00:00,  8.86batch/s, mse=5.58e+9]\n",
            "Epoch 156: 100%|██████████| 35/35 [00:03<00:00,  9.61batch/s, mse=5.59e+9]\n",
            "Epoch 157: 100%|██████████| 35/35 [00:04<00:00,  7.80batch/s, mse=1.36e+9]\n",
            "Epoch 158: 100%|██████████| 35/35 [00:03<00:00,  9.37batch/s, mse=6.27e+8]\n",
            "Epoch 159: 100%|██████████| 35/35 [00:03<00:00,  9.55batch/s, mse=2.57e+8]\n",
            "Epoch 160: 100%|██████████| 35/35 [00:04<00:00,  8.11batch/s, mse=8.87e+7]\n",
            "Epoch 161:   3%|▎         | 1/35 [00:00<00:04,  7.88batch/s, mse=9.74e+8]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "blue_patch = mpatches.Patch(color = 'blue', label = 'Train MSE')\n",
        "orange_patch = mpatches.Patch(color = 'orange', label = 'Validation MSE')\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "\n",
        "sns.lineplot(x=range(1,len(train_history)+1),y = train_history)\n",
        "sns.lineplot(x=range(1,len(test_history)+1),y = test_history)\n",
        "\n",
        "plt.xlabel('EPOCH')\n",
        "plt.ylabel('MSE')\n",
        "plt.legend(handles = [blue_patch,orange_patch])\n",
        "plt.title('Training and Validation loss');"
      ],
      "metadata": {
        "id": "m6mhdSqgvXzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "waltham = places_df[places_df.GeoId==2572600]\n",
        "actual = waltham.iloc[0].All_Revenue\n",
        "waltham_scaled = scaler.transform(waltham.drop(columns=['GeoId', 'All_Revenue']))\n",
        "prediction = model(torch.tensor(waltham_scaled, dtype=torch.float32)).item()\n",
        "print(f'actual: {int(actual):,} - predicted: {int(prediction):,}')\n",
        "print(f'difference: {int(abs(prediction-actual)):,}')"
      ],
      "metadata": {
        "id": "dGoI_U7QpXYL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}