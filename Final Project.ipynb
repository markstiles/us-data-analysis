{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPJABdWzyQCKVQ0BLtaSFXO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"Bs-Z_h-5kGi0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1698629480741,"user_tz":240,"elapsed":23101,"user":{"displayName":"Mark Stiles","userId":"10927884978511110673"}},"outputId":"ec2a2a88-3eca-46b7-888d-f58b3a79e359"},"outputs":[{"output_type":"stream","name":"stdout","text":["  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting torch-summary\n","  Downloading torch_summary-1.4.5-py3-none-any.whl (16 kB)\n","Installing collected packages: torch-summary\n","Successfully installed torch-summary-1.4.5\n"]}],"source":["! pip install torchviz -q\n","! pip install torch-summary"]},{"cell_type":"code","source":["# namespaces\n","import sklearn\n","import numpy as np\n","import matplotlib.patches as mpatches\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","import plotly.io as pio\n","pio.renderers.default = 'notebook'\n","import seaborn as sns\n","import time\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# functions\n","from sklearn.preprocessing import MinMaxScaler\n","from torchsummary import summary"],"metadata":{"id":"w-TVKKGQkL8e","executionInfo":{"status":"ok","timestamp":1698629497915,"user_tz":240,"elapsed":12193,"user":{"displayName":"Mark Stiles","userId":"10927884978511110673"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["class Model(nn.Module):\n","    def __init__(self):\n","        super(Model, self).__init__()\n","        self.fc1 = nn.Linear(4, 16)\n","        self.fc2 = nn.Linear(16, 32)\n","        self.fc3 = nn.Linear(32, 1)\n","\n","    def forward(self, x):\n","        x = torch.sigmoid(self.fc1(x))\n","        x = torch.sigmoid(self.fc2(x))\n","        x = self.fc3(x)\n","\n","        return x"],"metadata":{"id":"X798ey2YkMBh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# download data and select the close column\n","# https://raw.githubusercontent.com/markstiles/us-data-analysis/main/places_data.csv\n","places_df = pd.read_csv('https://raw.githubusercontent.com/markstiles/us-data-analysis/main/places_data.csv')"],"metadata":{"id":"6PzIT5qMkMDw","executionInfo":{"status":"ok","timestamp":1698630120810,"user_tz":240,"elapsed":1238,"user":{"displayName":"Mark Stiles","userId":"10927884978511110673"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["print(places_df.columns.unique())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MMd5VaczM5q3","executionInfo":{"status":"ok","timestamp":1698630130433,"user_tz":240,"elapsed":203,"user":{"displayName":"Mark Stiles","userId":"10927884978511110673"}},"outputId":"4be663ab-41df-4839-a5d8-cabcb976822f"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Index(['Unnamed: 0', 'GeoId', 'Place_Name', 'State_Abbr', 'State_Name', 'Type',\n","       'All_Employers', 'All_Employees', 'All_Payroll', 'All_Revenue',\n","       ...\n","       'Wholesale_Employee_Per_Employer', 'Wholesale_Revenue_Per_Employer',\n","       'Wholesale_Avg_Payroll_Per_Employee',\n","       'Wholesale_Population_Per_Employer', 'Income_Per_Revenue',\n","       'Industry_Count', 'Revenue_Per_Person', 'Profit_Per_Person',\n","       'Performance', 'Population_Range'],\n","      dtype='object', length=301)\n"]}]},{"cell_type":"code","source":["# fit, transform and reshape data\n","fit_data = MinMaxScaler().fit(gme).transform(gme).reshape(-1)"],"metadata":{"id":"srFZxSHKkMGI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# creating sequential data\n","x_data, y_data = create_sequences(fit_data, 4)\n","\n","# split data into ranges for training, testing and validation set\n","pos_one = 4600\n","pos_two = 4900\n","\n","x_train = x_data[:pos_one]\n","y_train = y_data[:pos_one]\n","\n","x_val = x_data[pos_one:pos_two]\n","y_val = y_data[pos_one:pos_two]\n","\n","x_test = x_data[pos_two:]\n","y_test = y_data[pos_two:]"],"metadata":{"id":"PGUdJlQ-kMIh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = Model()\n","\n","summary(Model(), input_size = (4022,4))"],"metadata":{"id":"MfP78i3HkMKw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# the goal would be to try to generate a series of networks to find the optimal one by randomly selecting the number of layers and neurons per layer. Also could iterate through the loss functions\n","# need to run a vanilla network to set a baseline"],"metadata":{"id":"WnT3wxNpl7AI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# train settings\n","num_epochs = 300\n","learning_rate = 0.01\n","batch_size = 10\n","epoch_batch_size = 10\n","\n","# list for storing loss\n","train_lss = []\n","val_loss = []\n","\n","# loss functiom\n","criterion = torch.nn.MSELoss() # mean-squared error for regression\n","\n","# initialization of Adam optimizer\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","#optimizer = torch.optim.SGD(lstm.parameters(), lr=learning_rate)\n","\n","# train the model\n","for epoch in range(num_epochs):\n","\n","    # take a batch at a time\n","    for i in range(0, len(x_train), batch_size):\n","\n","      # pull the current batch\n","      x_batch = x_train[i:i+batch_size]\n","      y_batch = y_train[i:i+batch_size].reshape(10,1)\n","\n","      # calculate the loss\n","      loss = criterion(model(x_batch), y_batch)\n","\n","      # run back prop\n","      optimizer.zero_grad()\n","      loss.backward()\n","      optimizer.step()\n","\n","    # store and print the training and validation loss every epoch batch\n","    if epoch % epoch_batch_size == 0:\n","      train_lss.append(loss.item())\n","\n","      #accuracy = (y_pred.round() == y).float().mean()\n","\n","      # calculate and store the validation loss (and don't calculate gradient because this is not training data)\n","      with torch.no_grad():\n","          val_lss = criterion(model(x_batch).float(), y_batch)\n","          val_loss.append(val_lss.item())\n","\n","      print(f\"Epoch: {epoch:d}, training loss: {loss.item():1.5f} , validation loss: {val_lss.item():1.5f}\")"],"metadata":{"id":"UsVIN7qtkMNA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# print out loss\n","blue_patch = mpatches.Patch(color = 'blue', label = 'Train MSE')\n","green_patch = mpatches.Patch(color = 'orange', label = 'Validation MSE')\n","\n","plt.figure(figsize=(10,6))\n","\n","sns.lineplot(x=range(1,int(num_epochs/10)+1),y = train_lss)\n","sns.lineplot(x=range(1,int(num_epochs/10)+1),y = val_loss)\n","\n","plt.xlabel('EPOCH')\n","plt.ylabel('MSE')\n","plt.legend(handles = [blue_patch,green_patch])\n","plt.title('Training and Validation loss');"],"metadata":{"id":"wjGluJ7lkbGA"},"execution_count":null,"outputs":[]}]}